{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPE_Lecture_4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNY638AEQB3EvvfRa6kGZHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pogba666/DeepLearning/blob/main/HPE_Lecture_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5wmIr7KtfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0fb6cd-cb08-4680-cab6-9a28ffa06746"
      },
      "source": [
        "% tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlauglwQ2EQ",
        "outputId": "122be3fc-e9a5-48e0-c205-71ed762d3f97"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "imdb = keras.datasets.imdb\r\n",
        "hp_dict_size = 10000  # HyperParameter choose based on frequency of usage\r\n",
        "(xtrain, ytrain), (xtest, ytest) = imdb.load_data(num_words=hp_dict_size)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/datasets/imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbmTIEy_ZZKE",
        "outputId": "16cbb93a-c44f-4dc6-d769-320ed1e3257e"
      },
      "source": [
        "print(ytrain[:10])\r\n",
        "# Gives a sentiment\r\n",
        "# 1 - Positive\r\n",
        "# 0 - Negative"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x__srzIHZoD3",
        "outputId": "8b2396ee-eee6-4b2e-923b-08a74f729253"
      },
      "source": [
        "wordIndex = imdb.get_word_index()\r\n",
        "# print(wordIndex[42])\r\n",
        "print(wordIndex['hello'])\r\n",
        "# Both options done to check if number used as word or word is tokenised as number\r\n",
        "# Ranking of words given based on frequency of occurence"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV6t_qIFaA1O",
        "outputId": "610442a0-7ae9-43e2-c9c6-55fba6ebb74f"
      },
      "source": [
        "print(ytrain[1])\r\n",
        "print(xtrain[1])    # Gives numbers list as output"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQmgmyJvbbW8",
        "outputId": "1ac60f91-a822-46dd-e861-a8ee5f253b73"
      },
      "source": [
        "# This dictionary switches words and encoding from wordIndex dictionary so that we can reverse engineer the output of xtrain\r\n",
        "dictionary = { encoding:word for word,encoding in wordIndex.items() }\r\n",
        "dictionary[42]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"it's\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "zv96mGUWb15s",
        "outputId": "e9e3e640-6e4f-4d63-e567-8d9c5877b578"
      },
      "source": [
        "# dictionary[0]   # word * 0 = 0\r\n",
        "#  NLP -> Rules\r\n",
        "# <PAD> -> 0 => Similar to padding in CV\r\n",
        "# <START> -> 1 => Starting of a sentence\r\n",
        "# <UNK> -> Unkown -> anything which we cannot make sense of\r\n",
        "# <UNUSED> -> Unused\r\n",
        "# These 4 have to be added manually to any dictionary before performing any function on it\r\n",
        "\r\n",
        "word_index = { word:(encoding + 3) for word, encoding in wordIndex.items() }\r\n",
        "word_index['<PAD>'] = 0\r\n",
        "word_index['<START>'] = 1\r\n",
        "word_index['<UNK>'] = 2\r\n",
        "word_index['<UNUSED>'] = 3\r\n",
        "\r\n",
        "dictionary = { encoding:word for word,encoding in word_index.items() }\r\n",
        "\r\n",
        "def decoder(review):\r\n",
        "    decoder_review = [dictionary.get(word) for word in review]\r\n",
        "    sentence = ' '.join(decoder_review)\r\n",
        "    return sentence\r\n",
        "\r\n",
        "print(ytrain[2])\r\n",
        "decoder(xtrain[2])\r\n",
        "# We get gibberish because we have to manipulate the data using NLP Rules"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNK> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZAMGXU2i9yr",
        "outputId": "a1aebcbf-ada3-4a04-9dca-a824e9f91492"
      },
      "source": [
        "lengths = []\r\n",
        "for x in range(20):\r\n",
        "  lengths.append(len(xtrain[x]))\r\n",
        "print(lengths)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[218, 189, 141, 550, 147, 43, 123, 562, 233, 130, 450, 99, 117, 238, 109, 129, 163, 752, 212, 177]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLBCjQJ2c2kC"
      },
      "source": [
        "xtrain_padded = keras.preprocessing.sequence.pad_sequences(xtrain, value = 0,\r\n",
        "                                                           padding='post',\r\n",
        "                                                           truncating='post',\r\n",
        "                                                           maxlen=256)\r\n",
        "\r\n",
        "xtest_padded = keras.preprocessing.sequence.pad_sequences(xtest, value = 0,\r\n",
        "                                                           padding='post',\r\n",
        "                                                           truncating='post',\r\n",
        "                                                           maxlen=256)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "xWTE6yfUh8aL",
        "outputId": "87ae0336-b55c-43c1-a004-8baebbeb9341"
      },
      "source": [
        "decoder(xtrain_padded[2])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNK> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7SgKqIiHTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1951798f-4da4-4d3f-cf7a-155f9bb42e66"
      },
      "source": [
        "xtrain_padded[2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,   14,   47,    8,   30,   31,    7,    4,  249,  108,    7,\n",
              "          4, 5974,   54,   61,  369,   13,   71,  149,   14,   22,  112,\n",
              "          4, 2401,  311,   12,   16, 3711,   33,   75,   43, 1829,  296,\n",
              "          4,   86,  320,   35,  534,   19,  263, 4821, 1301,    4, 1873,\n",
              "         33,   89,   78,   12,   66,   16,    4,  360,    7,    4,   58,\n",
              "        316,  334,   11,    4, 1716,   43,  645,  662,    8,  257,   85,\n",
              "       1200,   42, 1228, 2578,   83,   68, 3912,   15,   36,  165, 1539,\n",
              "        278,   36,   69,    2,  780,    8,  106,   14, 6905, 1338,   18,\n",
              "          6,   22,   12,  215,   28,  610,   40,    6,   87,  326,   23,\n",
              "       2300,   21,   23,   22,   12,  272,   40,   57,   31,   11,    4,\n",
              "         22,   47,    6, 2307,   51,    9,  170,   23,  595,  116,  595,\n",
              "       1352,   13,  191,   79,  638,   89,    2,   14,    9,    8,  106,\n",
              "        607,  624,   35,  534,    6,  227,    7,  129,  113,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "Qdn7CiXZjD6H",
        "outputId": "f1fdc3b3-fed1-44e6-fccf-64a9aa24d9a9"
      },
      "source": [
        "decoder(xtrain_padded[7])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> the <UNK> tells the story of the four hamilton siblings teenager francis <UNK> <UNK> twins <UNK> joseph <UNK> <UNK> <UNK> <UNK> the <UNK> david samuel who is now the surrogate parent in charge the <UNK> move house a lot <UNK> is unsure why is unhappy with the way things are the fact that his brother's sister kidnap <UNK> murder people in the basement doesn't help relax or calm <UNK> nerves either francis <UNK> something just isn't right when he eventually finds out the truth things will never be the same again br br co written co produced directed by mitchell <UNK> phil <UNK> as the butcher brothers who's only other film director's credit so far is the april <UNK> day 2008 remake enough said this was one of the <UNK> to die <UNK> at the 2006 after dark <UNK> or whatever it's called in keeping with pretty much all the other's i've seen i thought the <UNK> was complete total utter crap i found the character's really poor very unlikable the slow moving story failed to capture my imagination or sustain my interest over it's 85 a half minute too long <UNK> minute duration the there's the awful twist at the end which had me laughing out loud there's this really big <UNK> build up to what's inside a <UNK> thing in the <UNK> basement it's eventually revealed to be a little boy with a teddy is that really supposed to scare us is that really supposed to shock us is that really something that\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD_mqs0DjH85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}