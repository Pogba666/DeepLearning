{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPE_Lecture_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1lo9UxmMn9ELEpCQMf46s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pogba666/DeepLearning/blob/main/HPE_Lecture_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5wmIr7KtfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9696d38c-0913-4272-f6e0-6feb7b69c950"
      },
      "source": [
        "% tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOlauglwQ2EQ",
        "outputId": "3d96a89f-68e4-4ac6-823e-94b8d29bf05f"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "imdb = keras.datasets.imdb\r\n",
        "hp_dict_size = 10000  # HyperParameter choose based on frequency of usage\r\n",
        "(xtrain, ytrain), (xtest, ytest) = imdb.load_data(num_words=hp_dict_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/datasets/imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/datasets/imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbmTIEy_ZZKE",
        "outputId": "59cd485c-edf9-4e23-eac7-9c36e699d00d"
      },
      "source": [
        "print(ytrain[:10])\r\n",
        "# Gives a sentiment\r\n",
        "# 1 - Positive\r\n",
        "# 0 - Negative"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x__srzIHZoD3",
        "outputId": "8c93371d-0492-48ff-e5ff-5767742cf71a"
      },
      "source": [
        "wordIndex = imdb.get_word_index()\r\n",
        "# print(wordIndex[42])\r\n",
        "print(wordIndex['hello'])\r\n",
        "# Both options done to check if number used as word or word is tokenised as number\r\n",
        "# Ranking of words given based on frequency of occurence"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV6t_qIFaA1O",
        "outputId": "a3dc77d2-0ce9-42b8-ca00-7732c86f0d89"
      },
      "source": [
        "print(ytrain[1])\r\n",
        "print(xtrain[1])    # Gives numbers list as output"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WQmgmyJvbbW8",
        "outputId": "65b4c616-32f7-4074-bc19-ae5ff43e67c0"
      },
      "source": [
        "# This dictionary switches words and encoding from wordIndex dictionary so that we can reverse engineer the output of xtrain\r\n",
        "dictionary = { encoding:word for word,encoding in wordIndex.items() }\r\n",
        "dictionary[42]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"it's\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "zv96mGUWb15s",
        "outputId": "4c3453cd-2ebb-4355-ca57-e720e2400f44"
      },
      "source": [
        "# dictionary[0]   # word * 0 = 0\r\n",
        "#  NLP -> Rules\r\n",
        "# <PAD> -> 0 => Similar to padding in CV\r\n",
        "# <START> -> 1 => Starting of a sentence\r\n",
        "# <UNK> -> Unkown -> anything which we cannot make sense of\r\n",
        "# <UNUSED> -> Unused\r\n",
        "# These 4 have to be added manually to any dictionary before performing any function on it\r\n",
        "\r\n",
        "word_index = { word:(encoding + 3) for word, encoding in wordIndex.items() }\r\n",
        "word_index['<PAD>'] = 0\r\n",
        "word_index['<START>'] = 1\r\n",
        "word_index['<UNK>'] = 2\r\n",
        "word_index['<UNUSED>'] = 3\r\n",
        "\r\n",
        "dictionary = { encoding:word for word,encoding in word_index.items() }\r\n",
        "\r\n",
        "def decoder(review):\r\n",
        "    decoder_review = [dictionary.get(word) for word in review]\r\n",
        "    sentence = ' '.join(decoder_review)\r\n",
        "    return sentence\r\n",
        "\r\n",
        "print(ytrain[2])\r\n",
        "decoder(xtrain[2])\r\n",
        "# We get gibberish because we have to manipulate the data using NLP Rules"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<START> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <UNK> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <UNK> this is to watch save yourself an hour a bit of your life\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLBCjQJ2c2kC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}