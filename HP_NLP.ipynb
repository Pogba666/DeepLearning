{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HP_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9FM5mDjYtK6z5zdLSFZ5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pogba666/DeepLearning/blob/main/HP_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVYRrUzaHE5v",
        "outputId": "865d7f43-ac7e-4252-92aa-c9628c5f49eb"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8c9q3X3HO9e"
      },
      "source": [
        "import spacy\r\n",
        "dictionary = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tMd952btHaWE",
        "outputId": "ac928eda-013e-4cf8-bfa4-6421290ca828"
      },
      "source": [
        "text = \"\"\" 'Mary had a little lamb, little lamb, little lamb!' \r\n",
        "Grass is green, sky is blue. \"What did you say?\"\r\n",
        "\r\n",
        "  'I am not present here', she said.\r\n",
        "\"\"\"\r\n",
        "tokens = dictionary(text)\r\n",
        "text[-2]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGQbjh7AHea_",
        "outputId": "ab71ea02-f025-4010-d5e3-0baa9b8da7a1"
      },
      "source": [
        "tokens[-2]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiOTqzptHllm",
        "outputId": "1e2171f5-1352-4427-c2bb-b0c44b713c38"
      },
      "source": [
        "tokens[0].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8532415787641010193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "tZjl6Pv0HpGH",
        "outputId": "a84b9061-4e4c-423c-c9f5-bd0a79b92f65"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')\r\n",
        "text = \"Peter is eating a sandwich\"\r\n",
        "tokens = nlp(text)\r\n",
        "from spacy import displacy # dependency trees \r\n",
        "displacy.render(tokens, style='dep', jupyter=True, options={'distance':100})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9fe83e71c50c4b61a5a8528f92eee7e4-0\" class=\"displacy\" width=\"550\" height=\"237.0\" direction=\"ltr\" style=\"max-width: none; height: 237.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Peter</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">eating</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"147.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">sandwich</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-0\" stroke-width=\"2px\" d=\"M70,102.0 C70,2.0 250.0,2.0 250.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,104.0 L62,92.0 78,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-1\" stroke-width=\"2px\" d=\"M170,102.0 C170,52.0 245.0,52.0 245.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M170,104.0 L162,92.0 178,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-2\" stroke-width=\"2px\" d=\"M370,102.0 C370,52.0 445.0,52.0 445.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M370,104.0 L362,92.0 378,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-3\" stroke-width=\"2px\" d=\"M270,102.0 C270,2.0 450.0,2.0 450.0,102.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-9fe83e71c50c4b61a5a8528f92eee7e4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M450.0,104.0 L458.0,92.0 442.0,92.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81afK_fIHtM7",
        "outputId": "eb03862a-d309-4a99-eab3-6f208f8e1ba7"
      },
      "source": [
        "f = open('text.txt','rt')\r\n",
        "content = f.read()\r\n",
        "nlp = spacy.load('en_core_web_sm')\r\n",
        "tokens = nlp(content) # TEXT-> TOKENS-> POS tagging is complete as per SPACY\r\n",
        "len(tokens) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk38AqajHzV1",
        "outputId": "0e3f39c0-8557-4e28-ddc9-c8d4f3544725"
      },
      "source": [
        "for i in range(50):\r\n",
        "  if(tokens[i].tag_ == 'NNS'): # PLURAL NOUNS, Named Entity Recognition\r\n",
        "    print(tokens[i].text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "games\n",
            "moments\n",
            "chances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hix6bEoJVqZ",
        "outputId": "25fef4e9-41c4-456e-a0d3-598f8adfd1c4"
      },
      "source": [
        "for i in range(250):\r\n",
        "  if(tokens[i].tag_ == 'NNS'): # PLURAL NOUNS, Named ENtity Recognition\r\n",
        "    print(tokens[i].text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "games\n",
            "moments\n",
            "chances\n",
            "points\n",
            "leaders\n",
            "contenders\n",
            "weeks\n",
            "points\n",
            "champions\n",
            "months\n",
            "games\n",
            "points\n",
            "champions\n",
            "times\n",
            "spells\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwfsESM7JZUZ",
        "outputId": "c6d198e3-aff5-4e48-a651-4390f7a96a6e"
      },
      "source": [
        "for i in range(10):\r\n",
        "  print(tokens[i].text + \" : \" + tokens[i].tag_ + \" : \"+ str(tokens[i].tag))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forget : VB : 14200088355797579614\n",
            "that : IN : 1292078113972184607\n",
            "there : EX : 15361090031084224697\n",
            "'s : VBZ : 13927759927860985106\n",
            "still : RB : 164681854541413346\n",
            "22 : CD : 8427216679587749980\n",
            "games : NNS : 783433942507015291\n",
            "of : IN : 1292078113972184607\n",
            "an : DT : 15267657372422890137\n",
            "arduous : JJ : 10554686591937588953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDYtuO8ZJeMY",
        "outputId": "096ea79b-3b8e-4b0d-8fe8-c9d9db3d0b9d"
      },
      "source": [
        "for i in range(20):\r\n",
        "  if(tokens[i].is_stop == True):\r\n",
        "    print(tokens[i].text + \" is a stop word!\")\r\n",
        "  print(tokens[i].text + \" : \" + tokens[i].lemma_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forget : forget\n",
            "that is a stop word!\n",
            "that : that\n",
            "there is a stop word!\n",
            "there : there\n",
            "'s is a stop word!\n",
            "'s : be\n",
            "still is a stop word!\n",
            "still : still\n",
            "22 : 22\n",
            "games : game\n",
            "of is a stop word!\n",
            "of : of\n",
            "an is a stop word!\n",
            "an : an\n",
            "arduous : arduous\n",
            "season : season\n",
            "to is a stop word!\n",
            "to : to\n",
            "play : play\n",
            ". : .\n",
            "\n",
            " : \n",
            "\n",
            "Forget : forget\n",
            "that is a stop word!\n",
            "that : that\n",
            "Liverpool : Liverpool\n",
            "'s is a stop word!\n",
            "'s : 's\n",
            "goal : goal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "220NvW2pJgwA",
        "outputId": "3213b861-746b-4973-b39d-4508607d17c4"
      },
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\r\n",
        "spacy_stopwords"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{\"'d\",\n",
              " \"'ll\",\n",
              " \"'m\",\n",
              " \"'re\",\n",
              " \"'s\",\n",
              " \"'ve\",\n",
              " 'a',\n",
              " 'about',\n",
              " 'above',\n",
              " 'across',\n",
              " 'after',\n",
              " 'afterwards',\n",
              " 'again',\n",
              " 'against',\n",
              " 'all',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'along',\n",
              " 'already',\n",
              " 'also',\n",
              " 'although',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'amount',\n",
              " 'an',\n",
              " 'and',\n",
              " 'another',\n",
              " 'any',\n",
              " 'anyhow',\n",
              " 'anyone',\n",
              " 'anything',\n",
              " 'anyway',\n",
              " 'anywhere',\n",
              " 'are',\n",
              " 'around',\n",
              " 'as',\n",
              " 'at',\n",
              " 'back',\n",
              " 'be',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'becomes',\n",
              " 'becoming',\n",
              " 'been',\n",
              " 'before',\n",
              " 'beforehand',\n",
              " 'behind',\n",
              " 'being',\n",
              " 'below',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'between',\n",
              " 'beyond',\n",
              " 'both',\n",
              " 'bottom',\n",
              " 'but',\n",
              " 'by',\n",
              " 'ca',\n",
              " 'call',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'could',\n",
              " 'did',\n",
              " 'do',\n",
              " 'does',\n",
              " 'doing',\n",
              " 'done',\n",
              " 'down',\n",
              " 'due',\n",
              " 'during',\n",
              " 'each',\n",
              " 'eight',\n",
              " 'either',\n",
              " 'eleven',\n",
              " 'else',\n",
              " 'elsewhere',\n",
              " 'empty',\n",
              " 'enough',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'everyone',\n",
              " 'everything',\n",
              " 'everywhere',\n",
              " 'except',\n",
              " 'few',\n",
              " 'fifteen',\n",
              " 'fifty',\n",
              " 'first',\n",
              " 'five',\n",
              " 'for',\n",
              " 'former',\n",
              " 'formerly',\n",
              " 'forty',\n",
              " 'four',\n",
              " 'from',\n",
              " 'front',\n",
              " 'full',\n",
              " 'further',\n",
              " 'get',\n",
              " 'give',\n",
              " 'go',\n",
              " 'had',\n",
              " 'has',\n",
              " 'have',\n",
              " 'he',\n",
              " 'hence',\n",
              " 'her',\n",
              " 'here',\n",
              " 'hereafter',\n",
              " 'hereby',\n",
              " 'herein',\n",
              " 'hereupon',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'him',\n",
              " 'himself',\n",
              " 'his',\n",
              " 'how',\n",
              " 'however',\n",
              " 'hundred',\n",
              " 'i',\n",
              " 'if',\n",
              " 'in',\n",
              " 'indeed',\n",
              " 'into',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'itself',\n",
              " 'just',\n",
              " 'keep',\n",
              " 'last',\n",
              " 'latter',\n",
              " 'latterly',\n",
              " 'least',\n",
              " 'less',\n",
              " 'made',\n",
              " 'make',\n",
              " 'many',\n",
              " 'may',\n",
              " 'me',\n",
              " 'meanwhile',\n",
              " 'might',\n",
              " 'mine',\n",
              " 'more',\n",
              " 'moreover',\n",
              " 'most',\n",
              " 'mostly',\n",
              " 'move',\n",
              " 'much',\n",
              " 'must',\n",
              " 'my',\n",
              " 'myself',\n",
              " \"n't\",\n",
              " 'name',\n",
              " 'namely',\n",
              " 'neither',\n",
              " 'never',\n",
              " 'nevertheless',\n",
              " 'next',\n",
              " 'nine',\n",
              " 'no',\n",
              " 'nobody',\n",
              " 'none',\n",
              " 'noone',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'nothing',\n",
              " 'now',\n",
              " 'nowhere',\n",
              " 'n‘t',\n",
              " 'n’t',\n",
              " 'of',\n",
              " 'off',\n",
              " 'often',\n",
              " 'on',\n",
              " 'once',\n",
              " 'one',\n",
              " 'only',\n",
              " 'onto',\n",
              " 'or',\n",
              " 'other',\n",
              " 'others',\n",
              " 'otherwise',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'out',\n",
              " 'over',\n",
              " 'own',\n",
              " 'part',\n",
              " 'per',\n",
              " 'perhaps',\n",
              " 'please',\n",
              " 'put',\n",
              " 'quite',\n",
              " 'rather',\n",
              " 're',\n",
              " 'really',\n",
              " 'regarding',\n",
              " 'same',\n",
              " 'say',\n",
              " 'see',\n",
              " 'seem',\n",
              " 'seemed',\n",
              " 'seeming',\n",
              " 'seems',\n",
              " 'serious',\n",
              " 'several',\n",
              " 'she',\n",
              " 'should',\n",
              " 'show',\n",
              " 'side',\n",
              " 'since',\n",
              " 'six',\n",
              " 'sixty',\n",
              " 'so',\n",
              " 'some',\n",
              " 'somehow',\n",
              " 'someone',\n",
              " 'something',\n",
              " 'sometime',\n",
              " 'sometimes',\n",
              " 'somewhere',\n",
              " 'still',\n",
              " 'such',\n",
              " 'take',\n",
              " 'ten',\n",
              " 'than',\n",
              " 'that',\n",
              " 'the',\n",
              " 'their',\n",
              " 'them',\n",
              " 'themselves',\n",
              " 'then',\n",
              " 'thence',\n",
              " 'there',\n",
              " 'thereafter',\n",
              " 'thereby',\n",
              " 'therefore',\n",
              " 'therein',\n",
              " 'thereupon',\n",
              " 'these',\n",
              " 'they',\n",
              " 'third',\n",
              " 'this',\n",
              " 'those',\n",
              " 'though',\n",
              " 'three',\n",
              " 'through',\n",
              " 'throughout',\n",
              " 'thru',\n",
              " 'thus',\n",
              " 'to',\n",
              " 'together',\n",
              " 'too',\n",
              " 'top',\n",
              " 'toward',\n",
              " 'towards',\n",
              " 'twelve',\n",
              " 'twenty',\n",
              " 'two',\n",
              " 'under',\n",
              " 'unless',\n",
              " 'until',\n",
              " 'up',\n",
              " 'upon',\n",
              " 'us',\n",
              " 'used',\n",
              " 'using',\n",
              " 'various',\n",
              " 'very',\n",
              " 'via',\n",
              " 'was',\n",
              " 'we',\n",
              " 'well',\n",
              " 'were',\n",
              " 'what',\n",
              " 'whatever',\n",
              " 'when',\n",
              " 'whence',\n",
              " 'whenever',\n",
              " 'where',\n",
              " 'whereafter',\n",
              " 'whereas',\n",
              " 'whereby',\n",
              " 'wherein',\n",
              " 'whereupon',\n",
              " 'wherever',\n",
              " 'whether',\n",
              " 'which',\n",
              " 'while',\n",
              " 'whither',\n",
              " 'who',\n",
              " 'whoever',\n",
              " 'whole',\n",
              " 'whom',\n",
              " 'whose',\n",
              " 'why',\n",
              " 'will',\n",
              " 'with',\n",
              " 'within',\n",
              " 'without',\n",
              " 'would',\n",
              " 'yet',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " '‘d',\n",
              " '‘ll',\n",
              " '‘m',\n",
              " '‘re',\n",
              " '‘s',\n",
              " '‘ve',\n",
              " '’d',\n",
              " '’ll',\n",
              " '’m',\n",
              " '’re',\n",
              " '’s',\n",
              " '’ve'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEwrs7f7JlM3",
        "outputId": "5b9c39d8-e90e-46c6-f91e-a5d1e51da3d0"
      },
      "source": [
        "tokens_wostopwords = []\r\n",
        "for token in tokens:\r\n",
        "  if(token.is_stop == False):\r\n",
        "    tokens_wostopwords.append(token.text)\r\n",
        "\r\n",
        "print(\" \".join(tokens_wostopwords))\r\n",
        "len(tokens_wostopwords)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forget 22 games arduous season play . \n",
            " Forget Liverpool goal difference superior tune . \n",
            " Forget nail - biting moments , string David de Gea saves missed Aston Villa chances - Manchester United level points leaders Liverpool , time long time , considered genuine title contenders . \n",
            " long title challenge lasts remains seen , excitement extinguished time final whistle sounds Anfield weeks ' time , fact Manchester United currently contention achievement . \n",
            " Let forget , year day United entered 2020 staggering 24 points eventual champions . \n",
            " Exactly months 10 games ago , Arsenal inflicted league defeat Ole Gunnar Solskjaer , points adrift champions . \n",
            " stage naïve declare United recent ascension cause Liverpool sleepless night , certainly add fascinating element race title . \n",
            " Liverpool company , multiple times season fact , Tottenham , Chelsea Southampton enjoying spells summit . \n",
            " seen , , time , feels different . Having strolled imperiously title season , wonder Liverpool respond having arch - rivals - team record 20 - flight crowns looking equal come end season - breathing necks . \n",
            " position Manchester United , start - challenge sustain right end . \n",
            " \" Aston Villa aiming - finish , \" said Sky Sports ' Darren Bent ahead kick - Old Trafford . \n",
            "\n",
            " statement raised eyebrows watching home - Dean Smith consistency quality finishing Liverpool , Manchester United , Manchester City , Tottenham , Leicester Chelsea ? \n",
            " , taken seven points possible 12 big - hitters season defeat United enhanced Bent words Villa fall away . \n",
            " United moment relax pulsating fixture Jack Grealish dancing space pitch , creating chances teammates - taken . Yes , Emiliano Martinez called seven saves 90 minutes United expected goal figure 2.64 , suggesting making stops Premier League goalkeepers expected . Villa 15 shots United 19 wasted numerous set - piece situations - took 10 corners failed create single chance - Dean Smith disappointed . day , walked away result . \n",
            " latest performance , following draw Chelsea , proves Villa capable gatecrashing months . \n",
            "\n",
            " Everton defeat West Ham reality check . went game - game winning run , start season . slice bad luck Yerry Mina deflection zipped path Tomas Soucek slot home saw Everton beaten Premier League time month end positive festive period . \n",
            " Richarlison starting XI James Rodriguez returning bench , hope Everton rediscover free - scoring touch stood good stead earlier season . \n",
            " attacking play dull finishing lacked direction - shots target . Dominic Calvert - Lewin failed find net fifth Premier League game having scored 11 goals 11 matches previously struggling lack service . striker muster shots - Abdoulaye Doucoure - Richarlison . \n",
            " Everton defence impressive evening . Jordan Pickford Seamus Coleman welcome return . Michael Keane rested , Mason Holgate moved middle alongside Mina , taking spots clearances ( respectively ) . Ancelotti said : \" think defence better offensive partners . \" \n",
            " Everton manager hoping injured players action Premier League game January 12 Wolves , hopefully improve lacklustre start 2021 . \n",
            "\n",
            " games days huge task , especially intensity Premier League . West Ham drawn previous games away trip Everton , especially recent form , easy task . \n",
            " coming West Ham , David Moyes spoken desire improve mentality players - field performances . Beating Everton certainly showed , Moyes saying : \" Everton gone second tonight come Goodison got result shows players playing . \" \n",
            " battle defences Goodison Park , West Ham better , particularly break . Everton offer attack , Darren Randolph - late addition injury Lukasz Fabianski warm - - called . \n",
            " Tomas Soucek proving superb addition , slotting home fifth goal season Yerry Mina deflection fell path - West Ham highest scorer Premier League . Declan Rice continues superb talent . \n",
            " Moyes inherited West Ham squad year ago , steel result . improvement clear West Ham head games Burnley West Brom renewed confidence . \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXBlpTELJo02"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}