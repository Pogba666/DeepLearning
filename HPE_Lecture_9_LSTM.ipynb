{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPE_Lecture_9_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6va/TEUF1JTnwZ7oRlWV5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pogba666/DeepLearning/blob/main/HPE_Lecture_9_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saVJ6YksvrpR",
        "outputId": "fdf8b0d3-c13d-4e40-b2b6-a1ee1de84bf3"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "print(tf.__version__)\r\n",
        "from tensorflow.contrib import rnn\r\n",
        "import random\r\n",
        "import collections\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXGPA3PoAEMy"
      },
      "source": [
        "def build_dataset(words):\r\n",
        "    count = collections.Counter(words).most_common()\r\n",
        "    dictionary = dict()\r\n",
        "    for word, _ in count:\r\n",
        "        dictionary[word] = len(dictionary)\r\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\r\n",
        "    return dictionary, reverse_dictionary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrjSwEnfAIB-"
      },
      "source": [
        "start_time = time.time()\r\n",
        "def elapsed(sec):\r\n",
        "  if sec<60:\r\n",
        "      return str(sec) + \" sec\"\r\n",
        "  elif sec<(60*60):\r\n",
        "      return str(sec/60) + \" min\"\r\n",
        "  else:\r\n",
        "    return (str(sec/(60*60)) + \" hr\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvjGarmuAJlR"
      },
      "source": [
        "logs_path = '/content/rnn_words'\r\n",
        "writer = tf.summary.FileWriter(logs_path)\r\n",
        "\r\n",
        "training_file = 'harry_maguire_interview.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XucXlA_B-Qr"
      },
      "source": [
        "def read_data(fname):\r\n",
        "    with open(fname) as f:\r\n",
        "        content = f.readlines()\r\n",
        "    content = [x.strip() for x in content]\r\n",
        "    content = [word for i in range(len(content)) for word in content[i].split()]\r\n",
        "    content = np.array(content)\r\n",
        "    return content"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76uofywyCAUy",
        "outputId": "2e1997ae-5eb4-410d-af63-2a11edc7581c"
      },
      "source": [
        "training_data = read_data(training_file)\r\n",
        "training_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Harry', 'Maguire', 'has', 'told', 'Inside', 'United', 'that',\n",
              "       'he', 'is', 'determined', 'to', 'create', 'a', 'legacy', 'at',\n",
              "       'the', 'club', 'like', 'some', 'of', 'our', 'great',\n",
              "       'centre-backs', 'of', 'the', 'past.The', 'in-form', 'defender',\n",
              "       'is', 'ready', 'to', 'make', 'his', '83rd', 'appearance', 'for',\n",
              "       'the', 'Reds', 'in', \"Wednesday's\", 'Premier', 'League', 'clash',\n",
              "       'at', 'Fulham', 'as', 'he', 'rapidly', 'closes', 'in', 'on', 'a',\n",
              "       'century', 'of', 'games', 'already,', 'following', 'his', 'move',\n",
              "       'from', 'Leicester', 'City', 'in', '2019.The', 'official', 'club',\n",
              "       'magazine', 'asked', 'how', 'much', 'it', 'would', 'mean', 'to',\n",
              "       'the', '27-year-old', 'if', 'he', 'could', 'make', 'his', 'mark',\n",
              "       'in', 'the', 'manner', 'of', 'the', 'likes', 'of', 'Rio',\n",
              "       'Ferdinand,', 'Nemanja', 'Matic,', 'Steve', 'Bruce,', 'Gary',\n",
              "       'Pallister', 'and', 'Martin', 'Buchan.“Yeah,', 'it', 'means',\n",
              "       'everything,”', 'Maguire', 'replied.', '“It’s', 'why', 'I',\n",
              "       'joined', 'this', 'club.', 'It’s', 'something', 'that,', 'in',\n",
              "       'the', 'future,', 'I', 'want', 'to', 'look', 'back', 'at', 'and',\n",
              "       'see', 'I’ve', 'played', 'numerous', 'times', 'for', 'this',\n",
              "       'club.“Seventy', 'or', '80-odd', 'games', 'in', 'such', 'a',\n",
              "       'short', 'period', 'is', 'a', 'great', 'start', 'for', 'me.',\n",
              "       'But', 'it’s', 'only', 'a', 'start,', 'I', 'feel', 'like', 'I’m',\n",
              "       'going', 'to', 'have', 'a', 'lot', 'of', 'years', 'at', 'this',\n",
              "       'club.', 'And', 'that’s', 'the', 'aim', '–', 'I', 'want', 'to',\n",
              "       'keep', 'playing,', 'I', 'want', 'to', 'keep', 'impressing,', 'I',\n",
              "       'want', 'to', 'keep', 'improving.', 'And', 'it’s', 'also', 'very',\n",
              "       'important', 'to', 'keep', 'improving', 'as', 'a', 'team,', 'I',\n",
              "       'think', 'that’s', 'the', 'main', 'thing.”Indeed,', 'the',\n",
              "       'captain', 'feels', 'the', 'team', 'is', 'improving', 'and',\n",
              "       'losing', 'some', 'of', 'the', 'callowness', 'that', 'was',\n",
              "       'perhaps', 'evident', 'at', 'times', 'last', 'season.', 'Ole',\n",
              "       'Gunnar', \"Solskjaer's\", 'side', 'was', 'the', 'youngest', 'in',\n",
              "       'the', 'division', 'and', 'an', 'inability', 'to', 'grind', 'out',\n",
              "       'results', 'when', 'not', 'at', 'our', 'best', 'cost', 'the',\n",
              "       'Reds.There', 'are', 'signs', 'in', '2020/21', 'that', 'this',\n",
              "       'is', 'being', 'addressed,', 'as', 'gritty', 'recent', '1-0',\n",
              "       'wins', 'over', 'Wolves', 'and', 'Burnley', 'suggest,', 'and', 'a',\n",
              "       'similarly', 'dogged', 'victory', 'at', 'Craven', 'Cottage', 'on',\n",
              "       'Wednesday', 'night', 'would', 'be', 'most', 'welcome.“For',\n",
              "       'sure,', 'it’s', 'a', 'talented', 'young', 'group,', 'and', 'it’s',\n",
              "       'definitely', 'the', 'most', 'talented', 'squad', 'I’ve', 'been',\n",
              "       'involved', 'in,”', 'he', 'continued.', '“We’ve', 'played', 'a',\n",
              "       'little', 'bit', 'young', 'and', 'a', 'little', 'bit', 'immature',\n",
              "       'at', 'times', 'in', 'games,', 'and', 'I', 'feel', 'that,', 'this',\n",
              "       'season,', 'it’s', 'nice', 'to', 'win', 'a', 'couple', 'of',\n",
              "       'games', 'without', 'playing', 'at', 'our', 'best.“I', 'think',\n",
              "       'last', 'season,', 'every', 'game', 'that', 'we', 'won', 'we',\n",
              "       'had', 'to', 'score', 'and', 'run', 'riot,', 'really,', 'we',\n",
              "       'had', 'to', 'play', 'at', 'a', 'top,', 'top', 'level.', 'But',\n",
              "       'it’s', 'nice', 'to', 'know', 'that', 'when', 'things', 'aren’t',\n",
              "       'going', 'great,', 'we', 'can', 'still', 'win', 'football',\n",
              "       'matches.', 'And', 'I', 'think', 'that’s', 'a', 'big', 'part',\n",
              "       'of', 'experience.”'], dtype='<U14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufEuYdxVCXZS"
      },
      "source": [
        "def build_dataset(words):\r\n",
        "    count = collections.Counter(words).most_common()\r\n",
        "    dictionary = dict()\r\n",
        "    for word, _ in count:\r\n",
        "        dictionary[word] = len(dictionary)\r\n",
        "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\r\n",
        "    return dictionary, reverse_dictionary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQujlRHxCDri",
        "outputId": "79fc5b36-0ec5-4b38-f2ae-e2d32cf4ac8b"
      },
      "source": [
        "dictionary, reverse_dictionary = build_dataset(training_data)\r\n",
        "dictionary['every']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_VwQ2OOCGm0"
      },
      "source": [
        "vocab_size = len(dictionary)\r\n",
        "\r\n",
        "# Learning Rate-> v=u+at \r\n",
        "# EPOCHS-> best LR? \r\n",
        "# LR_final = 0, LR_init = 0.001, t= EPOCH \r\n",
        "# degradation_rate = - (LR_final - LR_initial / EPOCHS ) \r\n",
        "\r\n",
        "# Parameters\r\n",
        "learning_rate = 0.001\r\n",
        "training_iters = 50000\r\n",
        "display_step = 1000\r\n",
        "n_input = 3\r\n",
        "\r\n",
        "# number of units in RNN cell\r\n",
        "n_hidden = 512"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPjJ6nekCffG"
      },
      "source": [
        "x = tf.placeholder(\"float\", [None, n_input, 1])\r\n",
        "y = tf.placeholder(\"float\", [None, vocab_size])\r\n",
        "\r\n",
        "# TF-> PLACEHOLDERS (input, output), VARIABLES (weights, bias) \r\n",
        "# RNN output node weights and biases\r\n",
        "weights = {\r\n",
        "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\r\n",
        "}\r\n",
        "biases = {\r\n",
        "    'out': tf.Variable(tf.random_normal([vocab_size]))\r\n",
        "}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJDjrCxrCiaF"
      },
      "source": [
        "def RNN(x, weights, biases):\r\n",
        "\r\n",
        "    # reshape to [1, n_input]\r\n",
        "    x = tf.reshape(x, [-1, n_input])\r\n",
        "    x = tf.split(x,n_input,1)\r\n",
        "\r\n",
        "    # 2-layer LSTM, each layer has n_hidden units.\r\n",
        "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\r\n",
        "\r\n",
        "   # rnn_cell = rnn.BasicLSTMCell(n_hidden)\r\n",
        "\r\n",
        "    # generate prediction\r\n",
        "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\r\n",
        "\r\n",
        "    # there are n_input outputs but\r\n",
        "    # we only want the last output\r\n",
        "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2sFXTelClIU",
        "outputId": "5a54cfc6-75a6-449f-dc5e-cf004cd13c14"
      },
      "source": [
        "# predictions will be compared against the Y (known output)\r\n",
        "pred = RNN(x, weights, biases) \r\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\r\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-910265cd051f>:8: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-13-910265cd051f>:8: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-13-910265cd051f>:13: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-14-1f2c5946c709>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMe4ysmJCnJ1"
      },
      "source": [
        "# Model evaluation\r\n",
        "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\r\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n",
        "\r\n",
        "# Initializing the variables\r\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O8E01AphCqnG",
        "outputId": "2389d847-5c89-4555-e61a-6a2094f9d261"
      },
      "source": [
        "with tf.Session() as session:\r\n",
        "    session.run(init)\r\n",
        "    step = 0\r\n",
        "    offset = random.randint(0,n_input+1)\r\n",
        "    end_offset = n_input + 1\r\n",
        "    acc_total = 0\r\n",
        "    loss_total = 0\r\n",
        "\r\n",
        "    writer.add_graph(session.graph)\r\n",
        "    while step < training_iters:\r\n",
        "        # Generate a minibatch. Add some randomness on selection process.\r\n",
        "        if offset > (len(training_data)-end_offset):\r\n",
        "            offset = random.randint(0, n_input+1)\r\n",
        "\r\n",
        "        symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\r\n",
        "        symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\r\n",
        "\r\n",
        "        symbols_out_onehot = np.zeros([vocab_size], dtype=float)\r\n",
        "        symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\r\n",
        "        symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\r\n",
        "\r\n",
        "        _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\r\n",
        "                                                feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\r\n",
        "        loss_total += loss\r\n",
        "        acc_total += acc\r\n",
        "        if (step+1) % display_step == 0:\r\n",
        "            print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\r\n",
        "                  \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\r\n",
        "                  \"{:.2f}%\".format(100*acc_total/display_step))\r\n",
        "            acc_total = 0\r\n",
        "            loss_total = 0\r\n",
        "            symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\r\n",
        "            symbols_out = training_data[offset + n_input]\r\n",
        "            symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval())]\r\n",
        "            print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\r\n",
        "        step += 1\r\n",
        "        offset += (n_input+1)\r\n",
        "    print(\"Optimization Finished!\")\r\n",
        "    print(\"Elapsed time: \", elapsed(time.time() - start_time))\r\n",
        "    print(\"Run on command line.\")\r\n",
        "    print(\"\\ttensorboard --logdir=%s\" % (logs_path))\r\n",
        "    #print(\"Point your web browser to: http://localhost:6006/\")\r\n",
        "    while True:\r\n",
        "        prompt = \"%s words: \" % n_input\r\n",
        "        sentence = input(prompt)\r\n",
        "        sentence = sentence.strip()\r\n",
        "        words = sentence.split(' ')\r\n",
        "        if len(words) != n_input:\r\n",
        "            continue\r\n",
        "        try:\r\n",
        "            symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\r\n",
        "            for i in range(32):\r\n",
        "                keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\r\n",
        "                onehot_pred = session.run(pred, feed_dict={x: keys})\r\n",
        "                onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval())\r\n",
        "                sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\r\n",
        "                symbols_in_keys = symbols_in_keys[1:]\r\n",
        "                symbols_in_keys.append(onehot_pred_index)\r\n",
        "            print(sentence)\r\n",
        "        except:\r\n",
        "            print(\"Word not in dictionary\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter= 1000, Average Loss= 5.400804, Average Accuracy= 3.90%\n",
            "['And', 'that’s', 'the'] - [aim] vs [look]\n",
            "Iter= 2000, Average Loss= 3.223780, Average Accuracy= 16.00%\n",
            "['last', 'season,', 'every'] - [game] vs [and]\n",
            "Iter= 3000, Average Loss= 3.262591, Average Accuracy= 25.30%\n",
            "['played', 'numerous', 'times'] - [for] vs [that,]\n",
            "Iter= 4000, Average Loss= 2.902745, Average Accuracy= 29.90%\n",
            "['and', 'a', 'little'] - [bit] vs [dogged]\n",
            "Iter= 5000, Average Loss= 2.446778, Average Accuracy= 39.60%\n",
            "['means', 'everything,”', 'Maguire'] - [replied.] vs [mean]\n",
            "Iter= 6000, Average Loss= 2.453912, Average Accuracy= 41.00%\n",
            "['similarly', 'dogged', 'victory'] - [at] vs [and]\n",
            "Iter= 7000, Average Loss= 2.470763, Average Accuracy= 41.50%\n",
            "['club', 'magazine', 'asked'] - [how] vs [is]\n",
            "Iter= 8000, Average Loss= 2.515714, Average Accuracy= 38.40%\n",
            "['results', 'when', 'not'] - [at] vs [sure,]\n",
            "Iter= 9000, Average Loss= 2.304387, Average Accuracy= 43.60%\n",
            "['the', 'past.The', 'in-form'] - [defender] vs [defender]\n",
            "Iter= 10000, Average Loss= 2.240649, Average Accuracy= 45.50%\n",
            "['a', 'team,', 'I'] - [think] vs [years]\n",
            "Iter= 11000, Average Loss= 2.105226, Average Accuracy= 49.00%\n",
            "['nice', 'to', 'know'] - [that] vs [that]\n",
            "Iter= 12000, Average Loss= 2.302231, Average Accuracy= 45.30%\n",
            "['of', 'years', 'at'] - [this] vs [this]\n",
            "Iter= 13000, Average Loss= 1.856703, Average Accuracy= 55.20%\n",
            "['we', 'had', 'to'] - [play] vs [score]\n",
            "Iter= 14000, Average Loss= 1.936401, Average Accuracy= 54.50%\n",
            "['it’s', 'only', 'a'] - [start,] vs [start,]\n",
            "Iter= 15000, Average Loss= 1.798586, Average Accuracy= 55.10%\n",
            "['it’s', 'nice', 'to'] - [win] vs [make]\n",
            "Iter= 16000, Average Loss= 1.672572, Average Accuracy= 58.30%\n",
            "['want', 'to', 'look'] - [back] vs [I]\n",
            "Iter= 17000, Average Loss= 1.554429, Average Accuracy= 60.30%\n",
            "['most', 'talented', 'squad'] - [I’ve] vs [game]\n",
            "Iter= 18000, Average Loss= 1.863810, Average Accuracy= 56.60%\n",
            "['he', 'could', 'make'] - [his] vs [it’s]\n",
            "Iter= 19000, Average Loss= 1.529821, Average Accuracy= 63.00%\n",
            "['signs', 'in', '2020/21'] - [that] vs [that]\n",
            "Iter= 20000, Average Loss= 1.598126, Average Accuracy= 59.90%\n",
            "['a', 'century', 'of'] - [games] vs [games]\n",
            "Iter= 21000, Average Loss= 1.614787, Average Accuracy= 58.50%\n",
            "['last', 'season.', 'Ole'] - [Gunnar] vs [that,]\n",
            "Iter= 22000, Average Loss= 1.666896, Average Accuracy= 60.50%\n",
            "['some', 'of', 'our'] - [great] vs [great]\n",
            "Iter= 23000, Average Loss= 1.485141, Average Accuracy= 64.60%\n",
            "['keep', 'improving.', 'And'] - [it’s] vs [it’s]\n",
            "Iter= 24000, Average Loss= 1.524127, Average Accuracy= 64.70%\n",
            "['know', 'that', 'when'] - [things] vs [things]\n",
            "Iter= 25000, Average Loss= 1.535403, Average Accuracy= 64.90%\n",
            "['that’s', 'the', 'aim'] - [–] vs [thing.”Indeed,]\n",
            "Iter= 26000, Average Loss= 1.425571, Average Accuracy= 65.70%\n",
            "['score', 'and', 'run'] - [riot,] vs [riot,]\n",
            "Iter= 27000, Average Loss= 1.369940, Average Accuracy= 66.80%\n",
            "['such', 'a', 'short'] - [period] vs [I]\n",
            "Iter= 28000, Average Loss= 1.461770, Average Accuracy= 64.60%\n",
            "['that,', 'this', 'season,'] - [it’s] vs [it’s]\n",
            "Iter= 29000, Average Loss= 1.267044, Average Accuracy= 68.20%\n",
            "['“It’s', 'why', 'I'] - [joined] vs [joined]\n",
            "Iter= 30000, Average Loss= 1.374311, Average Accuracy= 68.20%\n",
            "['Wednesday', 'night', 'would'] - [be] vs [it’s]\n",
            "Iter= 31000, Average Loss= 1.466427, Average Accuracy= 66.10%\n",
            "['mark', 'in', 'the'] - [manner] vs [past.The]\n",
            "Iter= 32000, Average Loss= 1.439926, Average Accuracy= 66.00%\n",
            "['recent', '1-0', 'wins'] - [over] vs [in]\n",
            "Iter= 33000, Average Loss= 1.187145, Average Accuracy= 71.90%\n",
            "['League', 'clash', 'at'] - [Fulham] vs [Fulham]\n",
            "Iter= 34000, Average Loss= 1.355863, Average Accuracy= 67.20%\n",
            "['evident', 'at', 'times'] - [last] vs [last]\n",
            "Iter= 35000, Average Loss= 1.134746, Average Accuracy= 71.60%\n",
            "['determined', 'to', 'create'] - [a] vs [a]\n",
            "Iter= 36000, Average Loss= 1.427884, Average Accuracy= 65.60%\n",
            "['improving.', 'And', 'it’s'] - [also] vs [also]\n",
            "Iter= 37000, Average Loss= 1.241744, Average Accuracy= 70.10%\n",
            "['nice', 'to', 'know'] - [that] vs [that]\n",
            "Iter= 38000, Average Loss= 1.308426, Average Accuracy= 67.10%\n",
            "['start,', 'I', 'feel'] - [like] vs [like]\n",
            "Iter= 39000, Average Loss= 1.179827, Average Accuracy= 72.70%\n",
            "['to', 'win', 'a'] - [couple] vs [couple]\n",
            "Iter= 40000, Average Loss= 1.184552, Average Accuracy= 71.30%\n",
            "['I', 'want', 'to'] - [look] vs [look]\n",
            "Iter= 41000, Average Loss= 1.135305, Average Accuracy= 72.60%\n",
            "['and', 'it’s', 'definitely'] - [the] vs [the]\n",
            "Iter= 42000, Average Loss= 0.985430, Average Accuracy= 75.50%\n",
            "['of', 'Rio', 'Ferdinand,'] - [Nemanja] vs [Nemanja]\n",
            "Iter= 43000, Average Loss= 0.958307, Average Accuracy= 77.30%\n",
            "['similarly', 'dogged', 'victory'] - [at] vs [and]\n",
            "Iter= 44000, Average Loss= 1.168533, Average Accuracy= 71.30%\n",
            "['2019.The', 'official', 'club'] - [magazine] vs [magazine]\n",
            "Iter= 45000, Average Loss= 1.189219, Average Accuracy= 73.20%\n",
            "['signs', 'in', '2020/21'] - [that] vs [that]\n",
            "Iter= 46000, Average Loss= 1.067790, Average Accuracy= 73.50%\n",
            "['century', 'of', 'games'] - [already,] vs [already,]\n",
            "Iter= 47000, Average Loss= 1.168553, Average Accuracy= 72.60%\n",
            "['Gunnar', \"Solskjaer's\", 'side'] - [was] vs [was]\n",
            "Iter= 48000, Average Loss= 1.247124, Average Accuracy= 71.70%\n",
            "['at', 'the', 'club'] - [like] vs [like]\n",
            "Iter= 49000, Average Loss= 1.133931, Average Accuracy= 72.30%\n",
            "['improving', 'as', 'a'] - [team,] vs [team,]\n",
            "Iter= 50000, Average Loss= 1.213995, Average Accuracy= 70.60%\n",
            "['to', 'know', 'that'] - [when] vs [when]\n",
            "Optimization Finished!\n",
            "Elapsed time:  34.498449273904164 min\n",
            "Run on command line.\n",
            "\ttensorboard --logdir=/content/rnn_words\n",
            "3 words: inside united that\n",
            "Word not in dictionary\n",
            "3 words: Inside United that\n",
            "Inside United that ready to make his 83rd appearance for move from his move from his move from his move from his move from his move from his move from his move from his move\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-520e6ca8e915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s words: \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu_r9dXaCy7L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}