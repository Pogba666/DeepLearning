{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPE_Lecture_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuwbTjcZObdacNn+4qOsgm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pogba666/DeepLearning/blob/main/HPE_Lecture_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHMTu8fQRSDo",
        "outputId": "d5f46b94-343c-4f66-c420-5238be1e642e"
      },
      "source": [
        "% tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j4kWjvBRWTF",
        "outputId": "cf0bd968-ee54-4fca-9656-c1d48111e16b"
      },
      "source": [
        "from keras import backend\r\n",
        "from keras.layers.core import Dense, Dropout, Flatten, Activation\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization\r\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDGTZ0IAbxSz"
      },
      "source": [
        "#N= 5\r\n",
        "HP_block1_conv_dim = 32\r\n",
        "HP_block2_conv_dim = 64\r\n",
        "HP_block3_conv_dim = 128\r\n",
        "HP_block4_conv_dim = 256\r\n",
        "HP_block5_dense_dim = 1024\r\n",
        "HP_small_pattern = (3,3) # UNCOMPRESSED or 1-2 compression IMAGES\r\n",
        "HP_large_pattern = (2,2) # 4 times compressed images from previous MP layers!!!\r\n",
        "HP_dropout_little =0.25\r\n",
        "HP_dropout_big = 0.50\r\n",
        "# HP_epochs, batch_size-> are now problems of the developer USING this model."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kex0Uz7CbzLp"
      },
      "source": [
        "class RacoonVGG:\r\n",
        "  @staticmethod\r\n",
        "  def build(height, width, depth, classes):\r\n",
        "    # assume that we are on TF, but if something else is detected, switch the dimension\r\n",
        "    input_shape = (height, width, depth)\r\n",
        "    channel_dim = -1 # last position \r\n",
        "    if backend.image_data_format() == 'channels_first':\r\n",
        "      input_shape = (depth, height, width)\r\n",
        "      channel_dim = 1\r\n",
        "\r\n",
        "      # BLOCK1\r\n",
        "    model.add(Conv2D(HP_block1_conv_dim,HP_small_pattern, padding='same',\r\n",
        "                     input_shape=input_shape))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_small_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 2\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block2_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "    \r\n",
        "    # COMPLEX BLOCK 3\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block3_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # COMPLEX BLOCK 4\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(Conv2D(HP_block4_conv_dim,HP_small_pattern, padding='same'))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization(axis=channel_dim))\r\n",
        "    model.add(MaxPooling2D(pool_size=HP_large_pattern))\r\n",
        "    model.add(Dropout(HP_dropout_little))\r\n",
        "\r\n",
        "    # BLOCK 5- Image Classification (OBJECT)\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(HP_block5_dense_dim))\r\n",
        "    model.add(Activation('relu'))\r\n",
        "    model.add(BatchNormalization())\r\n",
        "    model.add(Dropout(HP_dropout_big))\r\n",
        "    model.add(Dense(classes))\r\n",
        "    model.add(Activation('softmax'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Xil24SsASr"
      },
      "source": [
        "# NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngLD5jUjgw3y",
        "outputId": "cbffc41f-a360-463b-aafb-ea9aa6674621"
      },
      "source": [
        "# DICTIONARY method for NLP inputs \r\n",
        "sent = 'Manchester United is the best club in the world. Bruno Fernandes is the best midfielder in the world. Marcus Rashford is the most valuable footballer in the world.'\r\n",
        "corpus_lower = sent.lower()\r\n",
        "words = []\r\n",
        "for word in corpus_lower.split():\r\n",
        "  if word != '.':\r\n",
        "    word = word.replace('.','')\r\n",
        "    words.append(word)\r\n",
        "\r\n",
        "words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['manchester',\n",
              " 'united',\n",
              " 'is',\n",
              " 'the',\n",
              " 'best',\n",
              " 'club',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " 'bruno',\n",
              " 'fernandes',\n",
              " 'is',\n",
              " 'the',\n",
              " 'best',\n",
              " 'midfielder',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " 'marcus',\n",
              " 'rashford',\n",
              " 'is',\n",
              " 'the',\n",
              " 'most',\n",
              " 'valuable',\n",
              " 'footballer',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcL34MU_sDZl",
        "outputId": "1c21df4a-58c0-4b2b-83cd-772bd921c16e"
      },
      "source": [
        "unique_words = set(words)\r\n",
        "unique_words"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'best',\n",
              " 'bruno',\n",
              " 'club',\n",
              " 'fernandes',\n",
              " 'footballer',\n",
              " 'in',\n",
              " 'is',\n",
              " 'manchester',\n",
              " 'marcus',\n",
              " 'midfielder',\n",
              " 'most',\n",
              " 'rashford',\n",
              " 'the',\n",
              " 'united',\n",
              " 'valuable',\n",
              " 'world'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33owyqResFDG",
        "outputId": "ddf0f241-0376-4da9-d123-7516bc3cfb6d"
      },
      "source": [
        "word2int = {}\r\n",
        "int2word = {}\r\n",
        "vocab_size = len(unique_words)\r\n",
        "for i,word in enumerate(unique_words):\r\n",
        "  word2int[word] = i\r\n",
        "  int2word[i] = word \r\n",
        "print(word2int)\r\n",
        "print(int2word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bruno': 0, 'world': 1, 'fernandes': 2, 'valuable': 3, 'footballer': 4, 'manchester': 5, 'in': 6, 'marcus': 7, 'club': 8, 'rashford': 9, 'best': 10, 'midfielder': 11, 'the': 12, 'united': 13, 'most': 14, 'is': 15}\n",
            "{0: 'bruno', 1: 'world', 2: 'fernandes', 3: 'valuable', 4: 'footballer', 5: 'manchester', 6: 'in', 7: 'marcus', 8: 'club', 9: 'rashford', 10: 'best', 11: 'midfielder', 12: 'the', 13: 'united', 14: 'most', 15: 'is'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJhMgapCuzeE",
        "outputId": "247a1885-202d-47d5-eba6-f46a1136d557"
      },
      "source": [
        "raw_sentences = sent.split('.')\r\n",
        "sentences = []\r\n",
        "for sentence in raw_sentences:\r\n",
        "  sentences.append(sentence.split())\r\n",
        "\r\n",
        "print(sentences)\r\n",
        "# Extra sentence due to EOF"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Manchester', 'United', 'is', 'the', 'best', 'club', 'in', 'the', 'world'], ['Bruno', 'Fernandes', 'is', 'the', 'best', 'midfielder', 'in', 'the', 'world'], ['Marcus', 'Rashford', 'is', 'the', 'most', 'valuable', 'footballer', 'in', 'the', 'world'], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRsEduYUu3zi",
        "outputId": "da22f65c-3f86-4d31-afbb-e7ef6ddb1afd"
      },
      "source": [
        "sentences = sentences[:-1]\r\n",
        "sentences"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Manchester', 'United', 'is', 'the', 'best', 'club', 'in', 'the', 'world'],\n",
              " ['Bruno',\n",
              "  'Fernandes',\n",
              "  'is',\n",
              "  'the',\n",
              "  'best',\n",
              "  'midfielder',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world'],\n",
              " ['Marcus',\n",
              "  'Rashford',\n",
              "  'is',\n",
              "  'the',\n",
              "  'most',\n",
              "  'valuable',\n",
              "  'footballer',\n",
              "  'in',\n",
              "  'the',\n",
              "  'world']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y6KlHiAu6G9",
        "outputId": "23731a67-e2d0-4587-9ae3-30dd4f2b8223"
      },
      "source": [
        "# Autocomplete \r\n",
        "# [INPUT]-> 1 output word \r\n",
        "\r\n",
        "# ML Algo-> y = mx + c\r\n",
        "# y => next word\r\n",
        "# y = weights * inputs + bias \r\n",
        "# weights = 1-D filters\r\n",
        "# inputs-> words provided\r\n",
        "\r\n",
        "# next_word = weights * previous_word + bias \r\n",
        "# ALL POSSIBLE COMBINATIONS of WORD PAIRS \r\n",
        "\r\n",
        "# filter_pairs -> [prev, next]\r\n",
        "window_size = 2\r\n",
        "data = []\r\n",
        "for sentence in sentences:\r\n",
        "  for wordId,word in enumerate(sentence):\r\n",
        "    for nxword in sentence[max(wordId - window_size,0):min(wordId + window_size, len(sentence))+1]:\r\n",
        "      if nxword != word:\r\n",
        "        data.append([word,nxword])\r\n",
        "\r\n",
        "data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Manchester', 'United'],\n",
              " ['Manchester', 'is'],\n",
              " ['United', 'Manchester'],\n",
              " ['United', 'is'],\n",
              " ['United', 'the'],\n",
              " ['is', 'Manchester'],\n",
              " ['is', 'United'],\n",
              " ['is', 'the'],\n",
              " ['is', 'best'],\n",
              " ['the', 'United'],\n",
              " ['the', 'is'],\n",
              " ['the', 'best'],\n",
              " ['the', 'club'],\n",
              " ['best', 'is'],\n",
              " ['best', 'the'],\n",
              " ['best', 'club'],\n",
              " ['best', 'in'],\n",
              " ['club', 'the'],\n",
              " ['club', 'best'],\n",
              " ['club', 'in'],\n",
              " ['club', 'the'],\n",
              " ['in', 'best'],\n",
              " ['in', 'club'],\n",
              " ['in', 'the'],\n",
              " ['in', 'world'],\n",
              " ['the', 'club'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'in'],\n",
              " ['world', 'the'],\n",
              " ['Bruno', 'Fernandes'],\n",
              " ['Bruno', 'is'],\n",
              " ['Fernandes', 'Bruno'],\n",
              " ['Fernandes', 'is'],\n",
              " ['Fernandes', 'the'],\n",
              " ['is', 'Bruno'],\n",
              " ['is', 'Fernandes'],\n",
              " ['is', 'the'],\n",
              " ['is', 'best'],\n",
              " ['the', 'Fernandes'],\n",
              " ['the', 'is'],\n",
              " ['the', 'best'],\n",
              " ['the', 'midfielder'],\n",
              " ['best', 'is'],\n",
              " ['best', 'the'],\n",
              " ['best', 'midfielder'],\n",
              " ['best', 'in'],\n",
              " ['midfielder', 'the'],\n",
              " ['midfielder', 'best'],\n",
              " ['midfielder', 'in'],\n",
              " ['midfielder', 'the'],\n",
              " ['in', 'best'],\n",
              " ['in', 'midfielder'],\n",
              " ['in', 'the'],\n",
              " ['in', 'world'],\n",
              " ['the', 'midfielder'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'in'],\n",
              " ['world', 'the'],\n",
              " ['Marcus', 'Rashford'],\n",
              " ['Marcus', 'is'],\n",
              " ['Rashford', 'Marcus'],\n",
              " ['Rashford', 'is'],\n",
              " ['Rashford', 'the'],\n",
              " ['is', 'Marcus'],\n",
              " ['is', 'Rashford'],\n",
              " ['is', 'the'],\n",
              " ['is', 'most'],\n",
              " ['the', 'Rashford'],\n",
              " ['the', 'is'],\n",
              " ['the', 'most'],\n",
              " ['the', 'valuable'],\n",
              " ['most', 'is'],\n",
              " ['most', 'the'],\n",
              " ['most', 'valuable'],\n",
              " ['most', 'footballer'],\n",
              " ['valuable', 'the'],\n",
              " ['valuable', 'most'],\n",
              " ['valuable', 'footballer'],\n",
              " ['valuable', 'in'],\n",
              " ['footballer', 'most'],\n",
              " ['footballer', 'valuable'],\n",
              " ['footballer', 'in'],\n",
              " ['footballer', 'the'],\n",
              " ['in', 'valuable'],\n",
              " ['in', 'footballer'],\n",
              " ['in', 'the'],\n",
              " ['in', 'world'],\n",
              " ['the', 'footballer'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'in'],\n",
              " ['world', 'the']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR8TdWOIzkfQ",
        "outputId": "d555a3fc-47ac-4e99-d351-9a3fad0d0574"
      },
      "source": [
        "window_size = 1\r\n",
        "data_single = []\r\n",
        "for sentence in sentences:\r\n",
        "  for wordId,word in enumerate(sentence):\r\n",
        "    for nxword in sentence[max(wordId - window_size,0):min(wordId + window_size, len(sentence))+1]:\r\n",
        "      if nxword != word:\r\n",
        "        data_single.append([word,nxword])\r\n",
        "\r\n",
        "data_single"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Manchester', 'United'],\n",
              " ['United', 'Manchester'],\n",
              " ['United', 'is'],\n",
              " ['is', 'United'],\n",
              " ['is', 'the'],\n",
              " ['the', 'is'],\n",
              " ['the', 'best'],\n",
              " ['best', 'the'],\n",
              " ['best', 'club'],\n",
              " ['club', 'best'],\n",
              " ['club', 'in'],\n",
              " ['in', 'club'],\n",
              " ['in', 'the'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'the'],\n",
              " ['Bruno', 'Fernandes'],\n",
              " ['Fernandes', 'Bruno'],\n",
              " ['Fernandes', 'is'],\n",
              " ['is', 'Fernandes'],\n",
              " ['is', 'the'],\n",
              " ['the', 'is'],\n",
              " ['the', 'best'],\n",
              " ['best', 'the'],\n",
              " ['best', 'midfielder'],\n",
              " ['midfielder', 'best'],\n",
              " ['midfielder', 'in'],\n",
              " ['in', 'midfielder'],\n",
              " ['in', 'the'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'the'],\n",
              " ['Marcus', 'Rashford'],\n",
              " ['Rashford', 'Marcus'],\n",
              " ['Rashford', 'is'],\n",
              " ['is', 'Rashford'],\n",
              " ['is', 'the'],\n",
              " ['the', 'is'],\n",
              " ['the', 'most'],\n",
              " ['most', 'the'],\n",
              " ['most', 'valuable'],\n",
              " ['valuable', 'most'],\n",
              " ['valuable', 'footballer'],\n",
              " ['footballer', 'valuable'],\n",
              " ['footballer', 'in'],\n",
              " ['in', 'footballer'],\n",
              " ['in', 'the'],\n",
              " ['the', 'in'],\n",
              " ['the', 'world'],\n",
              " ['world', 'the']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOBER9iKznJ0"
      },
      "source": [
        "# ONE HOT ENCODING for my dictionary\r\n",
        "# EVERY WORD in my dictionary should be 1 hot encoded!!!\r\n",
        "\r\n",
        "def Encoder(datapointindex, vocab_size):\r\n",
        "  temp = np.zeros(vocab_size)\r\n",
        "  temp[datapointindex] = 1\r\n",
        "  return temp"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWJ6FQaL4vOj",
        "outputId": "28fd8607-3a62-4692-cee9-6392ed08c688"
      },
      "source": [
        "trainx = []\r\n",
        "trainy = []\r\n",
        "for worddata in data:\r\n",
        "  try:\r\n",
        "    trainx.append(Encoder(word2int[worddata[0].lower()], vocab_size))\r\n",
        "    trainy.append(Encoder(word2int[worddata[1].lower()], vocab_size))\r\n",
        "  except:\r\n",
        "    continue\r\n",
        "\r\n",
        "len(trainx)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBz5d9604yMI",
        "outputId": "8ea74dfa-bbea-4b0d-efdc-be1f5bfec3b0"
      },
      "source": [
        "len(trainy)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCFt13T4y-w"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}